# WebSocket 设备状态订阅优化方案

**日期**: 2025年10月16日  
**接口**: `/api/v1/device/online/status/ws`  
**目标**: 解决 WebSocket 直接订阅 MQTT 导致的架构问题

---

## 📊 现状问题

### 当前架构

```
WebSocket 请求
    ↓
API Handler
    ↓
创建独立 MQTT 客户端 ← 问题所在
    ↓
直接订阅 devices/status/{id}
```

### 存在的问题

1. **绕过 Flow 层**
   - 无法应用三种模式逻辑（心跳/超时/消息模式）
   - 数据不走 StatusFlow 统一处理
   - 与其他数据源（Kafka）处理逻辑不一致

2. **资源浪费**
   - 每个 WebSocket 创建一个 MQTT 客户端
   - 虽然实际连接数不多，但架构不合理

3. **数据源耦合**
   - 现在数据可能来自 Kafka 或 MQTT
   - 不能依赖上游 MQTT 订阅

---

## ✅ 优化方案

### 核心思路

**通过 Redis Pub/Sub 解耦**：
- 所有状态数据统一从 Flow 层出来
- StatusFlow 发布到 Redis
- WebSocket 订阅 Redis（而非 MQTT）
- 支持集群部署

---

## 🏗️ 新架构设计

### 数据流向

```
Kafka/MQTT → MQTTAdapter → Bus → StatusFlow
                                      ↓
                          1. 更新数据库
                          2. SSE 通知
                          3. 触发自动化
                          4. 🆕 发布到 Redis
                                      ↓
                          Redis PUBLISH device:{id}:status
                                      ↓
                          各实例的 WebSocket Handler
                                      ↓
                          推送给前端
```

### 关键设计点

#### 1. 频道设计

**采用多频道方案**（每设备一个频道）

- **频道命名**: `device:{device_id}:status`
- **原因**: 
  - 每个 WS 只关心 1 个设备
  - 精准投递，无冗余消息
  - 百万设备规模下，实际活跃频道很少（几十到几百）
  - Redis 对无订阅者的频道几乎无开销

**消息格式**:
```json
{
  "device_id": "xxx",
  "device_name": "温度传感器01",
  "is_online": true,
  "timestamp": 1697452800,
  "source": "status_message"
}
```

#### 2. WebSocket 处理流程

**连接建立**:
```
1. WebSocket 握手
2. 解析请求参数 (device_id)
3. 验证权限
4. 查询当前状态 (数据库/缓存) → 立即返回
5. 订阅 Redis channel: device:{id}:status
6. 进入消息循环
```

**消息处理**:
```
goroutine 1: 
  - 从 Redis Pub/Sub 接收消息
  - 转发到 WebSocket 连接

goroutine 2:
  - 处理 WebSocket 心跳 (ping/pong)
  - 检测连接断开
```

**连接关闭**:
```
1. 取消 Redis 订阅
2. 清理资源
3. 关闭 WebSocket
```

---

## 🔧 实现要点

### 1. StatusFlow 扩展

在 `internal/flow/status.go` 的 `processMessage()` 中：

```go
func (f *StatusFlow) processMessage(msg *DeviceMessage) {
    // ... 原有逻辑 ...
    
    // 更新数据库
    dal.UpdateDeviceStatus(device.ID, status)
    
    // 🆕 发布到 Redis
    f.publishToRedis(device, status, msg.Metadata["source"])
    
    // ... SSE、自动化等其他逻辑 ...
}

func (f *StatusFlow) publishToRedis(device *model.Device, status int16, source interface{}) {
    ctx := context.Background()
    channel := fmt.Sprintf("device:%s:status", device.ID)
    
    payload := map[string]interface{}{
        "device_id":   device.ID,
        "device_name": getDeviceName(device),
        "is_online":   status == 1,
        "timestamp":   time.Now().Unix(),
        "source":      source,
    }
    
    jsonData, _ := json.Marshal(payload)
    global.REDIS.Publish(ctx, channel, jsonData)
}
```

**要点**:
- 发布操作异步化（避免阻塞）
- 使用连接池（避免频繁创建连接）
- 错误处理（发布失败记录日志，不影响主流程）

### 2. WebSocket Handler 重构

在 `internal/api/telemetry_data.go` 中：

```go
func (*TelemetryDataApi) ServeDeviceStatusByWS(c *gin.Context) {
    // 1. WebSocket 握手
    conn, err := Wsupgrader.Upgrade(c.Writer, c.Request, nil)
    if err != nil {
        return
    }
    defer conn.Close()
    
    // 2. 解析设备ID和认证
    deviceID, claims, err := parseWSRequest(conn)
    if err != nil {
        return
    }
    
    // 3. 立即查询并返回当前状态
    currentStatus := getCurrentDeviceStatus(deviceID)
    conn.WriteMessage(websocket.TextMessage, currentStatus)
    
    // 4. 订阅 Redis
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    channel := fmt.Sprintf("device:%s:status", deviceID)
    pubsub := global.REDIS.Subscribe(ctx, channel)
    defer pubsub.Close()
    
    // 5. 启动两个 goroutine
    var wg sync.WaitGroup
    wg.Add(2)
    
    // goroutine 1: Redis → WebSocket
    go func() {
        defer wg.Done()
        for {
            msg, err := pubsub.ReceiveMessage(ctx)
            if err != nil {
                return
            }
            conn.WriteMessage(websocket.TextMessage, []byte(msg.Payload))
        }
    }()
    
    // goroutine 2: 处理 WebSocket 心跳
    go func() {
        defer wg.Done()
        defer cancel() // 触发 goroutine 1 退出
        
        for {
            _, msg, err := conn.ReadMessage()
            if err != nil {
                return
            }
            if string(msg) == "ping" {
                conn.WriteMessage(websocket.TextMessage, []byte("pong"))
            }
        }
    }()
    
    wg.Wait()
}
```

**要点**:
- 立即返回当前状态（用户体验）
- 优雅退出（goroutine 同步）
- 错误处理（连接断开、订阅失败）
- 支持心跳保活

### 3. 删除旧代码

**移除**:
- `mqtt/ws_subscribe/mqtt_client.go` 中的 `SubscribeOnlineOffline()` 方法
- 或整个 `ws_subscribe` 包（如果只用于状态订阅）

**保留**:
- 遥测数据的 WebSocket 订阅（如果还在用 MQTT 方式）
- 可以后续用同样思路优化

---

## 📈 方案优势

### 1. 架构一致性

| 方面 | 优化前 | 优化后 |
|------|--------|--------|
| **数据源** | 直接订阅 MQTT | 统一从 Flow 层 |
| **模式支持** | ❌ 不支持 | ✅ 完整支持三种模式 |
| **Kafka 支持** | ❌ 无法处理 | ✅ 自动支持 |
| **逻辑分散** | ⚠️ 两处 | ✅ 单一数据源 |

### 2. 性能和资源

| 指标 | 优化前 | 优化后 |
|------|--------|--------|
| **MQTT 连接** | N 个（N=WS数量） | 1 个（统一订阅层） |
| **Redis 订阅** | 0 | N 个（但 N 很小） |
| **消息延迟** | ~10ms | ~5ms（Redis 更快） |
| **集群支持** | ⚠️ 需要共享订阅 | ✅ 原生支持 |

### 3. 可扩展性

- ✅ 支持任意数据源（MQTT/Kafka/HTTP/...）
- ✅ 支持水平扩展（多实例）
- ✅ 统一监控和调试
- ✅ 后续功能易于添加

---

## 🎯 实施步骤

### Phase 1: StatusFlow 扩展（1-2小时）

1. 在 `StatusFlow` 添加 `publishToRedis()` 方法
2. 在 `processMessage()` 中调用发布
3. 配置 Redis 客户端（复用现有连接）
4. 测试发布功能（可以用 redis-cli 验证）

### Phase 2: WebSocket Handler 重构（2-3小时）

1. 重写 `ServeDeviceStatusByWS()` 函数
2. 添加 Redis 订阅逻辑
3. 处理 goroutine 同步和错误
4. 添加日志和监控

### Phase 3: 测试验证（2-4小时）

1. 单实例测试
   - 设备上线/下线
   - WebSocket 正常接收
   - 心跳保活

2. 集群测试
   - 多实例部署
   - 跨实例消息传递
   - 负载均衡

3. 三种模式测试
   - 无配置模式
   - 心跳模式
   - 超时模式

### Phase 4: 清理旧代码（30分钟）

1. 删除 `SubscribeOnlineOffline()` 方法
2. 清理相关导入
3. 更新文档

---

## 🔍 边界情况处理

### 1. WebSocket 断线重连

**场景**: 前端刷新页面，WebSocket 重连

**处理**:
- 重新查询当前状态（可能已变化）
- 重新订阅 Redis
- 不会丢失状态（总能拿到最新的）

### 2. Redis 连接失败

**降级方案**:
```go
if err := pubsub.Subscribe(...); err != nil {
    // 记录错误
    logrus.Error("Redis subscribe failed, falling back to polling")
    
    // 降级为轮询模式（每5秒查一次数据库）
    ticker := time.NewTicker(5 * time.Second)
    // ...
}
```

### 3. 设备状态在订阅前变化

**问题**: 查询状态 → 状态变化 → 订阅 Redis（丢失这一次变化）

**解决**:
- 可接受：下次变化会收到
- 或者：订阅后再查一次状态对比

### 4. 消息顺序性

**Redis Pub/Sub 不保证顺序**（虽然实际上基本有序）

**处理**:
- 前端根据 `timestamp` 判断
- 或者后端发送时带序号

---

## 📊 监控指标

建议添加的指标：

```go
// Prometheus metrics
var (
    redisPublishTotal = prometheus.NewCounter(...)
    redisPublishErrors = prometheus.NewCounter(...)
    wsConnectionsActive = prometheus.NewGauge(...)
    wsMessagesSent = prometheus.NewCounter(...)
)
```

关键指标：
- Redis 发布成功/失败次数
- 活跃 WebSocket 连接数
- 消息推送延迟
- 订阅频道数量

---

## 💡 后续优化方向

### 1. 遥测数据 WebSocket

可以用同样思路优化：
- StatusFlow 发布状态到 Redis
- TelemetryFlow 发布遥测到 Redis
- WebSocket 统一从 Redis 订阅

### 2. 批量订阅

如果将来需要设备列表页：
```go
// 订阅模式：device:*:status
// 但需要过滤 tenant_id
```

### 3. 消息压缩

如果消息量大：
- 使用 MessagePack 替代 JSON
- 或者使用 gzip 压缩

---

## 📝 总结

### 核心改动

1. ✅ StatusFlow 发布到 Redis (`device:{id}:status`)
2. ✅ WebSocket 订阅 Redis（而非 MQTT）
3. ✅ 删除 `SubscribeOnlineOffline()` 旧逻辑

### 关键优势

- ✅ 数据统一从 Flow 层出来
- ✅ 支持三种模式
- ✅ 支持集群部署
- ✅ 支持多数据源（Kafka/MQTT）
- ✅ 架构清晰易维护

### 工作量评估

- 开发时间: 4-6 小时
- 测试时间: 2-4 小时
- 总计: 1 个工作日

### 风险评估

- 风险: 低
- 回滚方案: 保留旧代码，配置开关控制
- 兼容性: 前端无需改动

---

**建议**: 优先实施此优化，对现有架构是重要的补充完善。
